{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "from model import *\n",
    "from input import NetworkInput\n",
    "from config import *\n",
    "\n",
    "\n",
    "from data import createFeaturesDescription\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "num_steps=32\n",
    "\n",
    "keep_prob=1\n",
    "keep_prob_recurrent=1\n",
    "keep_prob_dense_layer=1\n",
    "\n",
    "data_augmentation=True\n",
    "name_train='train'\n",
    "\n",
    "hidden_size=128\n",
    "num_layers=2\n",
    "\n",
    "stride = 2\n",
    "\n",
    "run_with_papermill=False #if true, verbose mode will be set to 2 (1 line/epoch)\n",
    "\n",
    "kernel_regularizer_l2=0\n",
    "recurrent_regularizer_l2=0\n",
    "\n",
    "#TODO use_HPRMS\n",
    "use_F0=False\n",
    "F0_binary_values=False\n",
    "\n",
    "use_deltas=False\n",
    "\n",
    "nb_epochs=30\n",
    "\n",
    "train_model=True\n",
    "save_weights=True\n",
    "\n",
    "\n",
    "load_weights=False\n",
    "weights_filename=\"./logdir/2020-10-29_17-50-58-size_3_128/weights/weights_2020-10-29_17-50-58.h5\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config=Config(batch_size, num_steps, \n",
    "              keep_prob=keep_prob, keep_prob_recurrent=keep_prob_recurrent, keep_prob_dense_layer=keep_prob_dense_layer,\n",
    "              hidden_size=hidden_size, num_layers=num_layers, \n",
    "              kernel_regularizer_l2=kernel_regularizer_l2, recurrent_regularizer_l2=recurrent_regularizer_l2)\n",
    "config=completedConfig(config) #take default params for unspecified params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_description=createFeaturesDescription(F0=use_F0) #Features RMS, RMS HP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"Danish\", \"Dutch\", \"English\", \"Finnish\",\n",
    "    \"French\", \"German\", \"Hungarian\", \"Italian\",\n",
    "    \"Japanese\", \"Korean\", \"Mandarin\", \"Polish\",\n",
    "    \"Portuguese\", \"Russian\", \"Spanish\",\n",
    "    \"Swedish\", \"Turkish\", \"Estonian\", \"Arabic\", \"Czech\", \"Romanian\",\n",
    "    \"Basque\", \"Catalan\"]\n",
    "\n",
    "#Remove languages with not enough data\n",
    "languages.remove(\"Czech\")\n",
    "languages.remove(\"Romanian\")\n",
    "\n",
    "# FIRST VERSION\n",
    "#languages = ['Danish', 'Russian', 'Mandarin', 'Finnish', 'Dutch', 'English', 'Hungarian', 'Swedish', \n",
    "#             'Italian', 'French', 'Japanese', 'German', 'Portuguese', 'Polish', 'Spanish', 'Korean']\n",
    "\n",
    "sets ={}\n",
    "\n",
    "set_folds=[0]\n",
    "\n",
    "sets_folds = {\"train\" : [0, 1, 2],\n",
    "        \"test\":[3,4],\n",
    "        \"test1\" : [3],\n",
    "        \"test2\" : [4]}\n",
    "\n",
    "set_name='train'\n",
    "sets[set_name] = NetworkInput(config, folder='./Scores', \n",
    "                     subfolder=[\"fold_{}/\".format(k_fold) for k_fold in sets_folds[set_name]],\n",
    "            stride=stride, verbose=True,                                    \n",
    "             languages=languages, name=set_name, features_description=features_description,\n",
    "                              F0_binary_values=F0_binary_values,\n",
    "                             data_augmentation=data_augmentation, use_deltas=use_deltas)\n",
    "\n",
    "set_name='test'\n",
    "sets[set_name] = NetworkInput(config, folder='./Scores', for_evaluation=True,\n",
    "        subfolder=[\"fold_{}/\".format(k_fold) for k_fold in sets_folds[set_name]],\n",
    "            stride=stride, verbose=True,                                    \n",
    "             languages=None, languages_model=languages, name=set_name,\n",
    "                features_description=features_description, \n",
    "             F0_binary_values=F0_binary_values,\n",
    "                use_deltas=use_deltas) #autodetect languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkInput=sets[\"train\"]\n",
    "networkInputTest=sets[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model(config, networkInput)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_weights:\n",
    "    model.load_weights(weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    #SUMMARIES\n",
    "    today=datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    logdir=f\"./logdir/{today}-{name_train}\"\n",
    "    \n",
    "    #summary_writer=tf.summary.create_file_writer(logdir)\n",
    "    #summary_writer.set_as_default()\n",
    "    \n",
    "    #write_summaries_step=networkInput.nbr_batchs//20  #now every epoch\n",
    "    #print(f'write summaries every {write_summaries_step} (non-splitted) batches')\n",
    "    \n",
    "    #OPTIM (NAG)\n",
    "    true_nb_batches=networkInput.nbr_batchs*networkInput.num_slices_by_example\n",
    "    true_nb_batches_test=networkInputTest.nbr_batchs*networkInputTest.num_slices_by_example\n",
    "    lr_0=0.2  #start: 0.2\n",
    "    lr_decay=0.93\n",
    "    optim=optimizers.SGD(momentum=0.9, nesterov=True) #l_rate=0.001\n",
    "\n",
    "    def lr_schedule(epoch):\n",
    "        lr = lr_0*lr_decay**(epoch-1)\n",
    "        tf.summary.scalar('learning rate', data=lr, step=epoch)\n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    #CALLBACKS\n",
    "    \n",
    "    #simplePBar=Simple_progressBar_callback(networkInput, min_step=0.05)\n",
    "\n",
    "    tensorboardCallback=TensorBoard(log_dir=logdir, histogram_freq=1, write_graph=True,\n",
    "              update_freq='epoch', profile_batch=2)  \n",
    "    #before:  update_freq=write_summaries_step*networkInput.num_slices_by_example,\n",
    "    forgetStates=Forget_states_callback(networkInput, model, verbose=False)\n",
    "    callbacksList=[forgetStates,lr_callback, tensorboardCallback]\n",
    "    \n",
    "#METRICS\n",
    "acc_slices=[AccuracyStateless(networkInput, ind_batch_compute=k) for k in range(networkInput.num_slices_by_example)]\n",
    "#top3_slices=[TopKAccuracyStateless(networkInput, k=3, ind_batch_compute=j) for j in range(networkInput.num_slices_by_example)]\n",
    "\n",
    "metricsList=[KL_divStateless(networkInput), crossEntropyStateless(networkInput)]\n",
    "metricsList+=acc_slices\n",
    "metricsList+=[TopKAccuracyStateless(networkInput, k=3)] #top3  end of seq\n",
    "#metricsList+=top3_slices\n",
    "\n",
    "KLLoss=tf.keras.losses.KLDivergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.compile(optimizer=optim, loss=KLLoss, metrics=metricsList)\n",
    "else:\n",
    "    model.compile(loss=KLLoss, metrics=metricsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_mode= 2 if run_with_papermill else 1\n",
    "    \n",
    "if train_model:\n",
    "    for epoch in range(nb_epochs):\n",
    "        model.fit(networkInput.sliced_batch, steps_per_epoch=true_nb_batches, initial_epoch=epoch, epochs=epoch+1,\n",
    "                  shuffle=False, verbose=verbose_mode, callbacks=callbacksList, validation_data=networkInputTest.sliced_batch, \n",
    "                 validation_steps=true_nb_batches_test)\n",
    "else: #evaluate\n",
    "    true_nb_batches=networkInputTest.nbr_batchs*networkInputTest.num_slices_by_example\n",
    "    forgetStates=Forget_states_callback(networkInputTest, model, verbose=False)\n",
    "    callbacksList=[forgetStates]\n",
    "    model.evaluate(networkInputTest.sliced_batch, verbose=verbose_mode, steps=true_nb_batches,callbacks=callbacksList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE WEIGHTS\n",
    "weights_dir=f\"{logdir}/weights\"\n",
    "if save_weights:\n",
    "    os.makedirs(weights_dir)\n",
    "    model.save_weights(f\"{weights_dir}/weights_{today}.h5\")\n",
    "\n",
    "#TODO\n",
    "#SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model: #save info on input/model\n",
    "    orig_stdout = sys.stdout\n",
    "    with open(f\"{logdir}/info.txt\", 'w') as f:\n",
    "        sys.stdout = f\n",
    "        print(name_train)\n",
    "        print(networkInput)\n",
    "        \n",
    "        model.summary()\n",
    "        print(config)\n",
    "        \n",
    "        print(networkInputTest)\n",
    "    \n",
    "    sys.stdout = orig_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
